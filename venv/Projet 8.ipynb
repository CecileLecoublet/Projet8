{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 8 - Déployer un modèle dans le cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La \"Fruits!\" cherche à proposer des solutions innovantes pour la récolte des fruits.\n",
    "\n",
    "La volonté de l’entreprise est de préserver la biodiversité des fruits en permettant des traitements spécifiques pour chaque espèce de fruits en développant des robots cueilleurs intelligents.\n",
    "Votre start-up souhaite dans un premier temps se faire connaître en mettant à disposition du grand public une application mobile qui permettrait aux utilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.<br>\n",
    "Vous êtes donc chargé de développer dans un environnement Big Data une première chaîne de traitement des données qui comprendra le preprocessing et une étape de réduction de dimension.\n",
    "\n",
    "Pour cela, nous allons utilisé la librairie : \"PySpark\", \"PySpark\" est une alternative plus puissante que Pandas Python.<br>\n",
    "PySpark permet le calcul en temps réel sur une grande quantité de données car il se concentre sur le traitement en mémoire. Il présente une faible latence.<br>\n",
    "PySpark nous permet d’atteindre une grande vitesse de traitement des données, qui est environ 100 fois plus rapide en mémoire et 10 fois plus rapide sur le disque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire :\n",
    "* [Introduction](#chapter1)\n",
    "* [PySpark](#chapter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m img_to_array, load_img\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./archive/fruits-360-original-size/fruits-360-original-size/Training/\"\n",
    "\n",
    "images = ['apple_6', 'cabbage_white_1', 'carrot_1', 'cucumber_1', 'eggplant_violet_1', 'pear_1', 'zucchini_1']\n",
    "\n",
    "fig = plt.figure(figsize =(15,5))\n",
    "for i in range(7):\n",
    "    ax = fig.add_subplot(3,3,i+1,xticks=[],yticks=[])\n",
    "    #fig.patch.set_facecolor('#E53090')\n",
    "    #Above code adds a background color for subplots you can change the hex color code as you wish\n",
    "    plt.title(images[i])\n",
    "    plt.axis(\"off\")\n",
    "    ax.imshow(load_img(path + images[i] +\"/r0_0.jpg\", target_size=(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des librairies de bases\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "Ouverture des dossiers images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/lecou/Projet 8/Projet8/archive/fruits-360-original-size/fruits-360-original-size/Training/apple_6/r0_0.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .master(\"local[1]\")\\\n",
    "                    .appName(\"SparkByExamples.com\")\\\n",
    "                    .config(\"spark.memory.offHeap.enabled\",\"true\")\\\n",
    "                    .config(\"spark.memory.offHeap.size\",\"10g\")\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = spark.read.format(\"image\").load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print((img.count(), len(img.columns)))\n",
    "print(img.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.show of DataFrame[image: struct<origin:string,height:int,width:int,nChannels:int,mode:int,data:binary>]>\n"
     ]
    }
   ],
   "source": [
    "print(img.show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pyspark_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fa3f01be26d825c0153fe3845c1c5c3ae207bfc1847e0bb473c3e0e5ca6e5fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
